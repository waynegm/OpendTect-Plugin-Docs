{
    "pages": [
        {
            "tags": "",
            "text": "",
            "title": "Search results",
            "url": "/OpendTect-Plugin-Docs/search.html"
        },
        {
            "tags": "",
            "text": "This is the documentation site for various plugins and external attribute scripts I have developed for the open source seismic interpretation system OpendTect . The plugins are made available under the terms of the GNU General Public License Version 3 .",
            "title": "OpendTect Plugins",
            "url": "/OpendTect-Plugin-Docs/index.html"
        },
        {
            "tags": "external-attribute filter",
            "text": "Script: Filtering/ex_spatial_filter_circular.py Description This Python ExternalAttrib script applies lowpass, highpass, bandpass or band reject circularly symmetric spatial filters. The filters are applied by direct spatial convolution using the MAXFLAT operators presented by Khan and Ohba (2001) . Filter responses Note that the filter cutoff or band pass/reject frequency is specified in Normalised Spatial Frequency. Normalised Frequency ranges from 0 to 1 at the spatial nyquist. Converting a spatial frequency in cycles/metre to the equivalent Normalised Spatial Frequency is as simple as dividing it by the spatial nyquist frequency. As written the filter does not take into account differences in spatial sampling in the inline and crossline directions. Examples This example uses a Low Pass filter to remove acquisition footprint from the F3 Demo dataset. FK spectrum of inline 425 Note the noise at 0.0133 cycles/metre or 0.67 normalised frequency (i.e. 0.0133/0.02). A spatial low pass filter with a normalised frequency cutoff of 0.5 is very effective at attenuating this acquisition footprint. FK spectrum of inline 425 after filter Input Parameters ex_spatial_filter.py input parameters NAME DESCRIPTION Stepout Determines the size of the convolution operator. Minimum of 9 (filter kernel size of 19) recommended. Type Filter type - Low Pass, High Pass, Band Pass or Band Reject. Normalised Spatial Frequency For Low Pass and High Pass filters this specifies the filter cutoff. For Band Pass/Reject filters this is the centre of the pass/reject band. The width of the band is hardwired to +/- 0.1 in the script. The filter cutoff corresponds to the half amplitude point.",
            "title": "Spatial Filter - Circular",
            "url": "/OpendTect-Plugin-Docs/external_attributes/Spatial_Filter_Circular.html"
        },
        {
            "tags": "external-attribute structure",
            "text": "Description These Python ExternalAttrib scripts implement various algorithms to estimate orientation, ie dip or dip azimuth. All scripts will estimate at least the following attributes: OUTPUT DESCRIPTION Inline Dip Event dip observed on a crossline in microseconds per metre for time surveys and millimetres per metre for depth surveys. Output can be positive or negative with the convention that events dipping towards larger inline numbers producing positive dips. Crossline Dip Event dip observed on an inline in microseconds per metre for time surveys and millimetres per metre for depth surveys. Output can be positive or negative with the convention that events dipping towards larger crossline numbers producing positive dips. True Dip Event dip in microseconds per metre for time surveys and millimetres per metre for depth surveys. Output is always positive. Dip Azimuth Azimuth of the True Dip direction relative to the survey orientation. Output ranges from -180 to 180 degrees. Positive azimuth is defined from the inline in the direction of increasing crossline numbers. Azimuth = 0 indicates that the dip is dipping in the direction of increasing crossline numbers. Azimuth = 90 indicates that the dip is dipping in the direction of increasing inline numbers. Some scripts may offer additional outputs such as a measure of event coherency or planarity. All of the scripts require the numba Python package. Orientation from gradients Script: ex_gradient_dip.py Calculates orientation from inline, crossline and Z gradients. No filtering is applied Unfiltered gradient dip - crossline dip on an inline Orientation from vector filtered gradients Script: ex_vf_gradient3_dip.py Uses Kroon's (2009) 3 point derivative filter to estimate data gradients. Next gradient normal unit vectors are determined and smoothed using a vector filter. NAME DESCRIPTION Output What to calculate - choice of inline dip, crossline dip, true dip or dip azimuth. Z window (+/-samples) Specifies the extent of the analysis cube in the Z direction. Number of Z samples in cube will be $ (2*Zwindow+1) $. Stepout Specifies the inline and crossline extent of the analysis cube. Number of samples in each direction will be $ (2*Stepout+1) $. Filter Choice of Mean Dip, L1 Vector Median or L2 Vector Median. The aperture of the vector filtering is $ (2*Zwindow-1) $ Z samples and $ (2*Stepout-1) $ samples in the inline and crossline direction. For example for a 5x5x5 analysis cube $(Zwindow=2, Stepout=2)$ the gradients and associated normal unit vectors are generated on a 3x3x3 cube and vector filtered. The outer samples are only used in the gradient calculation. Vector filtered gradient dip - crossline dip on an inline - 5x5x5 input Orientation by the gradient structure tensor Scripts: ex_gradient3_st_dip.py & ex_gradient5_st_dip.py Uses either Kroon's (2009) 3 point or the Farid and Simoncelli (2004) 5 point derivative filter to estimate data gradients which are then used to form the gradient structure tensor. NAME DESCRIPTION Output What to calculate - choice of inline dip, crossline dip, true dip or dip azimuth. Z window (+/-samples) Specifies the extent of the analysis cube in the Z direction. Number of Z samples in cube will be $ (2\\*Zwindow+1) $. Stepout Specifies the inline and crossline extent of the analysis cube. Number of samples in each direction will be $ (2\\*Stepout+1) $. For the ex_gradient3 script the structure tensor is formed from an aperture of $ (2*Zwindow-1) $ Z samples and $ (2*Stepout-1) $ samples in the inline and crossline direction. For the ex_gradient5 script the structure tensor is formed from an aperture of $ (2*Z_window-2) $ Z samples and $ (2*Stepout-2) $ samples in the inline and crossline direction. Gradient3 structure tensor dip - crossline dip on an inline - 5x5x5 input Orientation from the 3D complex trace phase Script: ex_phase3_dip.py Calculates orientation from the 3D complex trace phase gradients as per Barnes (2007) . Kroon's (2009) 3 point derivative filter is used to compute gradients. NAME DESCRIPTION Output What to calculate - choice of inline dip, crossline dip, true dip or dip azimuth. Z window (+/-samples) Specifies the length $ (2*Zwindow+1) $ of the time domain operator used to generate the complex analytic signal (recommend >= 15) Band Specifies the proportion of the frequency band to include when generating the complex analytic signal (recommend 0.9). Unfiltered phase dip - crossline dip on an inline Orientation from vector filtered 3D complex trace phase Script: ex_vf_phase3_dip.py Calculate orientation unit normal vectors using the 3D complex trace phase gradient and apply a vector filter. Kroon's (2009) 3 point filter used to compute gradients. NAME DESCRIPTION Output What to calculate - choice of inline dip, crossline dip, true dip or dip azimuth. Z window (+/-samples) Specifies the length $ (2*Zwindow+1) $ of the time domain operator used to generate the complex analytic signal (recommend >= 15) Stepout Specifies the inline and crossline extent of the analysis cube. Number of samples in each direction will be $ (2*Stepout+1) $. Filter Choice of Mean Dip, L1 Vector Median or L2 Vector Median. Vector Filter ZStepOut Specifies the extent of the analysis cube for vector filtering in the Z direction. Number of Z samples in cube will be $ (2*ZStepOut+1) $. Band Specifies the proportion of the frequency band to include when generating the complex analytic signal (recommend 0.9). The aperture of the vector filter is $ (2*ZStepOut+1) $ Z samples and $ (2*Stepout-1) $ samples in the inline and crossline direction. Mean Vector Filtered phase dip - crossline dip on an inline - 3x3x3 Orientation using the envelope weighted 3D complex trace phase structure tensor Script: ex_weighted_phase3_st_dip.py Forms a structure tensor from the 3D complex trace phase gradients. Tensor elements are weighted by the trace envelope as per Luo etal (2006) . Kroon's (2009) 3 point filter is used to compute gradients. NAME DESCRIPTION Output What to calculate - choice of inline dip, crossline dip, true dip or dip azimuth. Z window (+/-samples) Specifies the length $ (2*Zwindow+1) $ of the time domain operator used to generate the complex analytic signal (recommend >= 15) Stepout Specifies the inline and crossline extent of the analysis cube. Number of samples in each direction will be $ (2*Stepout+1) $. Tensor ZStepOut Specifies the extent of the analysis cube for vector filtering in the Z direction. Number of Z samples in cube will be $ (2*ZStepOut+1) $. Band Specifies the proportion of the frequency band to include when generating the complex analytic signal (recommend 0.9). The aperture of the structure tensor is $ (2*ZStepOut+1) $ Z samples and $ (2*Stepout-1) $ samples in the inline and crossline direction. Structure tensor phase dip - crossline dip on an inline - 3x3x3 tensor input |",
            "title": "Dip and Azimuth",
            "url": "/OpendTect-Plugin-Docs/external_attributes/DipandAzimuth.html"
        },
        {
            "tags": "external-attribute",
            "text": "Description These ExternalAttrib scripts estimate AVO intercept and gradient based on Shuey's 2 term approximation to the Zoeppritz  equation. Intercept and Gradient from 4 Angle Stacks Script: Miscellaneous/ex_angle_stacks_4_to_AVOIG.py Takes as input 4 angle stacks and the corresponding angles and fits a least squares line to the amplitude and $ sin^2(angle) $ at each sample point. Ouput includes the intercept, gradient and the correlation coefficient of the line fit. Input Parameters ex_angle_stacks_4_to_AVOIG.py input parameters For each input volume the corresponding incident angle must be provided.",
            "title": "AVO Intercept and Gradient",
            "url": "/OpendTect-Plugin-Docs/external_attributes/AVO_IG.html"
        },
        {
            "tags": "external-attribute filter",
            "text": "Script: ex_lpa_smooth.py Description This Python ExternalAttrib script can be used to filter noise while preserving steep dips. A region of data around each sample location is approximated by a second order 3D polynomial using gaussian weighted least squares. The approximation has the following form: $$ r_0+ r_1 * x + r_2 * y + r_3 * z + r_4 * x^2 + r_5 * y^2 + r_6 * z^2 +r_7 * x * y + r_8 * x * z + r_9 * y * z $$ where x (inline), y (crossline) and z (time/depth) are relative to the analysis location, ie the analysis location has x=y=z=0. This attribute calculates and outputs only the $ r_0 $ term of the local polynomial approximation. This provides a smoother version of the input with relatively minor smearing of steep dips and fault cuts. Increasing either the Weight Factor or size of the analysis volume (StepOut or Z window) increases the amount of smoothing. Examples Input Parameters LPA Smoothing external attribute input parameters NAME DESCRIPTION Z window (+/-samples) Specifies the extent of the analysis cube in the Z direction. Number of Z samples in cube will be $ 2 * Zwindow + 1 $. Stepout Specifies the inline and crossline extent of the analysis cube. Number of samples in each direction will be $ 2 * Stepout + 1 $. Weight Factor Determines the extent of the gaussian weight function used in the weighted least squares approximation.  The standard deviation of the gaussian weight function ($ \\sigma $) is related to this value by\n\n$$ \\sigma = min(2*Stepout, 2*Zwindow) * WeightFactor $$\n\nA value of 0.15 gives near zero weight for points at the smallest extent of the analysis cube. References Anisotropic Multidimensional Savitzky Golay kernels for Smoothing, Differentiation and Reconstruction Polynomial Expansion for Orientation and Motion Estimation",
            "title": "LPA Smoothing",
            "url": "/OpendTect-Plugin-Docs/external_attributes/LPA_Smooth.html"
        },
        {
            "tags": "external-attribute",
            "text": "Script: Miscellaneous/ex_add_noise.py Description This Python ExternalAttrib script adds gaussian distributed noise to an input signal. Examples This example shows an input signal with different levels of added noise. Input with varying levels of added noise Input Parameters ex_add_noise.py input parameters NAME DESCRIPTION S/N Ratio Desired signal to noise ratio.",
            "title": "Add Noise",
            "url": "/OpendTect-Plugin-Docs/external_attributes/Add_Noise.html"
        },
        {
            "tags": "external-attribute filter",
            "text": "Script: Filtering/ex_spatial_filter_rectangular.py Description This Python ExternalAttrib script applies lowpass, highpass, bandpass or band reject spatial filters with rectangular symmetry. The filters are applied by direct spatial convolution of a kernel formed by cascading two 1D MAXFLAT operators ( Khan and Ohba (2001) ). By setting the stepout in one direction to 0 the filter will be applied as a 1D spatial filter in the other direction. Note that the filter cutoff or band pass/reject frequency is specified in Normalised Spatial Frequency. Normalised Frequency ranges from 0 to 1 at the spatial nyquist. Converting a spatial frequency in cycles/metre to the equivalent Normalised Spatial Frequency is as simple as dividing it by the spatial nyquist frequency. Examples This example shows inline and crossline FK spectra after applying a 2D lowpass rectangular filter with inline and crossline normalised frequency cutoffs of 0.6 and 0.3 respectively. This example shows a timeslice at 300ms TWT from the F3 Demo dataset after applying a 1D spatial filter along the inlines (stepout of 0,9) with a crossline normalised frequency cutoff of 0.5. This example shows the timeslice at 300ms TWT from the F3 Demo dataset with the crossline lowpass filter above followed by a 1D bandreject spatial filter along the crosslines (stepout 9,0) with an inline normalised rejection frequency of 0.17. Input Parameters ex_spatial_filte_rectangular.py input parameters NAME DESCRIPTION Stepout Determines the size of the convolution operator. Minimum of 9 (filter kernel size of 19) recommended. Setting the stepout to zero will apply a 1D filter, e.g. a stepout of 0,9 will apply a 1D crossline frequency filter. Type Filter type - Low Pass, High Pass, Band Pass or Band Reject. Normalised Inline Spatial Frequency For Low Pass and High Pass filters this specifies the inline filter cutoff. For Band Pass/Reject filters this is the centre of the pass/reject band. The width of the band is hardwired to +/- 0.1 in the script. The filter cutoff corresponds to the half amplitude point. Normalised Xline Spatial Frequency For Low Pass and High Pass filters this specifies the crosslineline filter cutoff. For Band Pass/Reject filters this is the centre of the pass/reject band. The width of the band is hardwired to +/- 0.1 in the script. The filter cutoff corresponds to the half amplitude point.",
            "title": "Spatial Filter - Rectangular",
            "url": "/OpendTect-Plugin-Docs/external_attributes/Spatial_Filter_Rectangular.html"
        },
        {
            "tags": "external-attribute filter",
            "text": "Script: ex_vector_filter_dip.py Description This ExternalAttrib script can be used to apply a vector filter to orientation ( inline and crossline dip) data. The script offers a choice of mean vector, L1 vector median and L2 vector median filters. Initially the inline and crossline dip data are converted to a normal vector to the local orientation: $ [x_i, y_i, z_i] $. The Mean Vector Filter averages each of the vector components of the orientation normal vectors in the analysis cube:\n$$\n\\Big[x_f, y_f, z_f\\Big]  = \\frac{1}{N} \\Big[\\sum\\limits_{i}^N x_i, \\sum\\limits_{i}^N y_i, \\sum\\limits_{i}^N z_i\\Big]\n$$ The L1 vector filter finds the normal vector in the analysis cube whose sum of absolute distance from all the others is a minimum:\n$$\n\\Big[x_f, y_f, z_f\\Big] = argmin \\sum\\limits_{i}^N \\Big[|x_f-x_i| + |y_f-y_i| + |z_f-z_i|\\Big]\n$$ The L2 vector filter finds the normal vector in the analysis cube whose sum of squared distance from all the others is a minimum:\n$$\n\\Big[x_f, y_f, z_f\\Big] = argmin \\sum\\limits_{i}^N \\Big[(x_f-x_i)^2 + (y_f-y_i)^2 + (z_f-z_i)^2\\Big]\n$$ The filtered orientation can be output as any of the following: OUTPUT DESCRIPTION Inline Dip Event dip observed on a crossline in microseconds per metre for time surveys and millimetres per metre for depth surveys. Output can be positive or negative with the convention that events dipping towards larger inline numbers producing positive dips. Crossline Dip Event dip observed on an inline in microseconds per metre for time surveys and millimetres per metre for depth surveys. Output can be positive or negative with the convention that events dipping towards larger crossline numbers producing positive dips. True Dip Event dip in microseconds per metre for time surveys and millimetres per metre for depth surveys. Output is always positive. Dip Azimuth Azimuth of the True Dip direction relative to the survey orientation. Output ranges from -180 to 180 degrees. Positive azimuth is defined from the inline in the direction of increasing crossline numbers. Azimuth = 0 indicates that the dip is dipping in the direction of increasing crossline numbers. Azimuth = 90 indicates that the dip is dipping in the direction of increasing inline numbers. The script requires the Numba Python package. Examples Unfiltered phase dip - crossline dip on an inline Mean vector filtered phase dip - 3x3x3 (Stepout and ZWindow of 1) L1 vector median filtered phase dip - 3x3x3 (Stepout and ZWindow of 1) L2 vector median filtered phase dip - 3x3x3 (Stepout and ZWindow of 1) Input Parameters ex_vector_filter_dip.py input parameters NAME DESCRIPTION Output What to calculate - choice of inline dip, crossline dip, true dip or dip azimuth. Z window (+/-samples) Specifies the extent of the analysis cube in the Z direction. Number of Z samples in cube will be $ 2*Zwindow+1 $. Stepout Specifies the inline and crossline extent of the analysis cube. Number of samples in each direction will be $ 2*Stepout+1 $. Filter Choice of Mean Dip, L1 Vector Median or L2 Vector Median.",
            "title": "Vector Filter",
            "url": "/OpendTect-Plugin-Docs/external_attributes/Vector_Filters.html"
        },
        {
            "tags": "external-attribute",
            "text": "Zero Crossing Block Script: Miscellaneous/ex_zc_block.py Description This Python ExternalAttrib script blocks a seismic trace between zero crossings. The block amplitude is determined by the min/max of the interval blocked. The script requires the Numba Python package. Examples This example shows the attribute output (black wiggle) over the input (variable density). To get a blocky wiggle display interpolation has to be turned off in the 2D viewer properties. Zero crossing block Input Parameters ex_zc_block.py input parameters There are no input parameters other than selection of the input volume.",
            "title": "ZC Block",
            "url": "/OpendTect-Plugin-Docs/external_attributes/ZC_Block.html"
        },
        {
            "tags": "external-attribute",
            "text": "Script: Miscellaneous/ex_correlation.py Description This Python ExternalAttrib script provides an alternative to the builtin OpendTect Match Delta attribute to measure time shifts between similar events in different seismic volumes. This script uses local normalised cross correlation to determine the relative Z shift between 2 data volumes. Aside from the estimate of relative Z shift the attribute can also output the correlation value. The correlation value which ranges from 0 (low correlation) to 1 (high correlation) provides a quantitative assessment of the reliability of the Z shift estimate. The script requires the Numba Python package. Examples This example provides a comparison of this external attribute script (left) with the Match Delta attribute (right) for a depth section and itself shifted up by 13 metres. The Match Delta attribute output is much noisier albiet it can be calulated much quicker. This example shows the Correlation Quality output for the same data as above. Correlation quality Input Parameters ex_correlation.py input parameters NAME DESCRIPTION Output What to calculate - choice of the Z shift in millisecs or metres or the corresponding correlation coefficient. Z window (+/-samples) This in conjunction with the Max Lag parameter determines the length of the segments cross correlated. $ SegmentLength = 2*(Zwindow - MaxLag)+1 $. Max Lag (samples) Specifies maximum number of samples to search for the maximum correlation. Note the user has to ensure that Z window is greater than Max Lag otherwise the script will exit with errors.",
            "title": "Time Delay Estimation",
            "url": "/OpendTect-Plugin-Docs/external_attributes/Z_Delay_Est.html"
        },
        {
            "tags": "",
            "text": "AVO Intercept and Gradient Add Noise Dip and Azimuth LPA Smoothing Spatial Filter - Circular Spatial Filter - Rectangular Time Delay Estimation Vector Filter ZC Block",
            "title": "External Attributes",
            "url": "/OpendTect-Plugin-Docs/external_attributes/index.html"
        },
        {
            "tags": "",
            "text": "FAQ Can't find an answer here - then submit an issue on Github . Geopackage Export plugin isn't loading The GeopackageExport plugin  requires access to external files (DLL's on Windows and lib*.so on Linux). These should have been included in the binary package for the plugins. On Windows the folder containing the plugin and support DLL's must be added to the PATH environment variable. Do this by either: Editing/Adding the PATH environment variable for the System or User (Control Panel>System and Security>System - Advanced system settings - Environment Variables) Adding a line like \"@set PATH=%HOMEPATH%.od\\bin\\win64\\Release;%PATH%\" (adjust \"%HOMEPATH%.od\\bin\\win64\\Release\" to reflect your installation) to the bat script used to start OpendTect Building plugins that require Madagascar To build plugins that use the Madagascar libraries (eg LTFAttrib ) you need to set the RSFROOT environment variable before building the plugins. export RSFROOT=/opt/OpendTect_4/4.6.0/Madagascar\n    cmake.\n    make Plugins not loading Try manually loading the plugin. Check the OpendTect log file for error messages and see if there is already a solution outlined elsewhere in this page. Per-user Installation and Multiple OpendTect versions The OpendTect-6.4-plugins won't work in OpendTect 6.2 and the OpendTect-6.2-plugins won't work in OpendTect 6.4. Here is a way to use the plugins with mutliple versions of OpendTect. Use the OD_USER_PLUGIN_DIR environment variable For Windows 1.Create ODPlugins\\6.4.0 and ODPlugins\\6.2.0 folders in the C:\\Users\\%username% folder 2.Install the OpendTect-6.2-plugins in the 6.2.0 folder and the OpendTect-6.4-plugins in the 6.4.0 folder as per the Installation instructions. 3.Create a \"bat\" file to start each version of OpendTect that sets the OD_USER_PLUGIN_DIR environment variable to the appropriate folder before starting OpendTect. Here is what odt_6_4.bat might look like: @set OD_USER_PLUGIN_DIR=%HOMEPATH%\\ODPlugins\\6.4.0\nstart \"\" \"C:\\Program Files\\OpendTect\\6.4.0\\bin\\win64\\Release\\od_start_dtect.exe\" For Linux 1.Create ODPlugins\\6.4.0 and ODPlugins\\6.2.0 folders in the users home directory mkdir ~/ODPlugins\n    mkdir ~/ODPlugins/6.4.0 \n    mkdir ~/ODPlugins/6.2.0 2.Install the OpendTect-6.4-plugins in the users 6.4.0 folder and the OpendTect-6.2-plugins in the 6.2.0 folder as per the Installation instructions. 3.Create executable shell scripts to start each version of OpendTect that sets the OD_USER_PLUGIN_DIR to the appropriate folder before starting OpendTect. Here is what odt_6_4.csh might look like: #!/bin/csh -f\n    setenv OD_USER_PLUGIN_DIR \"$HOME/ODPlugins/6.4.0\"\n    /path to OpendTect 6.4/start_dtect libstdc++.so.6: version 'GLIBCXX_3.4.??' not found This happens when the plugin is built with a gcc version different to the version used to build OpendTect. Solutions are: (Easy and seems to work ok but could break something) Rename the libstdc++.so.6 file in the OpendTect installation bin/lux64 folder to say old_libstdc++.so.6 and restart OpendTect. (Hard) Install the same version of gcc that OpendTect was built with and rebuild the plugin. (Hardest) Build OpendTect from source using your installed gcc.",
            "title": "Frequently Asked Questions",
            "url": "/OpendTect-Plugin-Docs/installation/faq.html"
        },
        {
            "tags": "",
            "text": "Installation For both Linux and Windows there are 2 alternatives, site wide installation or per-user installation. Linux Sitewide Installation To install the plugins into the OpendTect program folder (eg /opt/seismic/OpendTect/6.4.0/ ): Copy the contents of the bin/lux64/Release/ folder in the tgz file to /opt/seismic/OpendTect/6.4.0/bin/lux64/Release/ ; Copy the contents of the plugins/lux64/ folder in the tgz file to /opt/Seismic/OpendTect/6.4.0/plugins/lux64/ ; and Restart OpendTect. Per-user Installation On Linux it is also possible to install the plugin files in a users .od folder. Note that the OpendTect-6.4.0-plugins won't work in OpendTect 6.2.0 and the OpendTect-6.2.0-plugins won't work in OpendTect 6.4.0. See the Frequently Asked Questions for a workaround if you want a per-user installation and want to run multiple versions of OpendTect. Copy the contents of the bin/lux64/Release/ folder in the tgz file to the users .od/bin/lux64/Release/ folder; Copy the contents of the plugins/lux64/ folder in the tgz file to the users .od/plugins/lux64/ folder; and Restart OpendTect. Windows Sitewide Installation To install the plugins into the OpendTect program folder (eg c:\\Program Files\\Opendtect\\6.4.0 ): Copy the contents of the bin\\win64\\Release\\ folder in the zip file to c:\\Program Files\\Opendtect\\6.4.0\\bin\\win64\\Release\\ ; Copy the contents of the plugins\\win64\\ folder in the zip file to c:\\Program Files\\Opendtect\\6.4.0\\plugins\\win64\\ ; and Restart OpendTect. Per-user Installation On Windows it is also possible to install the plugin files in a users .od folder. Note that the OpendTect-6.4.0-plugins won't work in OpendTect 6.2 and the OpendTect-6.2-plugins won't work in OpendTect 6.4. See the Frequently Asked Questions for a workaround if you want a per-user installation and want to run multiple versions of OpendTect. Copy the contents of the bin\\win64\\Release\\ folder in the zip file to the users C:\\Users\\%username%\\.od\\bin\\win64\\Release\\ folder; Copy the contents of the plugins\\win64\\ folder in the zip file to the users C:\\Users\\%username%\\.od\\plugins\\win64\\ folder; and Restart OpendTect.",
            "title": "Installation",
            "url": "/OpendTect-Plugin-Docs/installation/installation.html"
        },
        {
            "tags": "",
            "text": "Download Binary Distribution Compiled versions of the plugins for Linux x86_64 and Windows x86_64 are available for download at the links below. Note that the plugin  version installed should match the OpendTect version. For example the 6.4 series of plugin binaries should work with all OpendTect 6.4 releases but won't work with OpendTect 6.0 or 6.2. OpendTect Version 6.4 OS LATEST Linux Download Linux_6.4.7 Windows Download Win_6.4.7 OpendTect Version 6.2 OS LATEST Linux Download Linux_6.2.4 Windows Download Win_6.2.4 OpendTect Version 6.0 OS LATEST Linux Download Linux_6.0.4 Windows Download Win_6.0.4 OpendTect Version 5 OS LATEST Linux Download Linux_5.0.10 Windows Download Win_5.0.10 OpendTect Version 4 OS LATEST Windows and Linux Download 4.6.0",
            "title": "Download Binary Distribution",
            "url": "/OpendTect-Plugin-Docs/installation/download-binary.html"
        },
        {
            "tags": "",
            "text": "Building from Source Linux These instructions are for Linux. Some of the attributes won't build (eg LTFAttrib )unless Madagascar is installed. Download the source for the plugins for the appropriate version of OpendTect from Github Latest (OpendTect 6.4) OpendTect v5 OpendTect v4 Use the OpendTect installation manager to install the OpendTect developer packages and install any other packages required for compiling and building code for your operating environment as per the OpendTect Programmer's Manual Start OpendTect Select the Utilities-Tools-Create Plugin Devel. Env. menu item to create a development work folder (eg /home/user/ODWork). Unzip the attribute source zip archive downloaded in step 1 in the development work folder. This will overwrite the CMakeLists.txt in the development work folder and add the plugin source folders to the plugin folder. Optionally edit CMakeCache.txt in the development work folder and change Debug to Release. Optionally set the environment variable pointing to your Madagascar install export RSFROOT=/opt/OpendTect_4/4.6.0/Madagascar Open a terminal, cd to the development work folder and type: cmake .\n    make This should create the binary files for each plugin, lib*.so and libui*.so, in the bin folder (eg in ODWork/bin/lux64/Release/) and four *.alo files for each plugin in the root of the development work folder. If you don't have Madagascar installed or RSFROOT is not set the plugins that depend on the Madagascar libraries (eg LTFAttrib ) won't build and there will be error messages. These error messages can be ignored if you don't want the Madagascar dependent attributes. Windows These instructions are for Windows. Note that the attributes that require Madagascar (eg LTFAttrib ) cannot be built on Windows. Download the source for the plugins for the appropriate version of OpendTect from Github Latest (OpendTect 6.4) OpendTect v5 OpendTect v4 Use the OpendTect installation manager to install the OpendTect developer packages and install any other packages required for compiling and building code for your operating environment as per the OpendTect Programmer's Manual Start OpendTect Select the Utilities-Tools-Create Plugin Devel. Env. menu item to create a development work folder (eg c:\\Users\\user\\ODWork). Unzip the attribute source zip archive downloaded in step 1 in the development work folder. This will overwrite the CMakeLists.txt in the development work folder and add the plugin source folders to the plugin folder. Follow the instructions in the OpendTect Programmer's Manual to configure and build the plugins. This should create the binary files for each plugin in the bin folder (eg in ODWork\\bin\\win64\\Release). On Windows you must use \"Release\" build plugins with the \"Release\" version of OpendTect.",
            "title": "Building from Source",
            "url": "/OpendTect-Plugin-Docs/installation/building-from-source.html"
        },
        {
            "tags": "",
            "text": "Download Binary Distribution Installation Building from Source Frequently Asked Questions",
            "title": "Installation",
            "url": "/OpendTect-Plugin-Docs/installation/index.html"
        },
        {
            "tags": "plugin",
            "text": "This plugin, for the open source seismic interpretation platform OpendTect Version 6.4.0 or later, creates a constant Z value 3D horizon which covers the extent of 2D and 3D seismic data in an OpendTect survey/project. With the horizon displayed it is possible to draw fault polygons and grid clipping polygons that extend beyond the 3D survey definition. These can then be used in the Grid 2D-3D Horizon plugin to produce structure maps that extend across both 2D and 3D seismic interpretation in an OpendTect survey/project. Description The plugin adds a \"Covering 2D-3D Data Extent...\" item to the \"Processing|Create Horizon Output\" menu item which opens a dialog box for: Specifying a constant Z value for the output horizon Selecting 2D and 3D seismic data that the horizon should cover Specifying the name of the generated horizon Example of an horizon created by the plugin and various polygons drawn across the extent of the 2D and 3D seismic data in the project Input Parameters DataExtentHorizon plugin input dialog",
            "title": "DataExtentHorizon",
            "url": "/OpendTect-Plugin-Docs/plugins/DataExtentHorizon.html"
        },
        {
            "tags": "plugin",
            "text": "This attibute plugin for the open source seismic interpretation platform OpendTect Version 6.0.0 or later calculates inline, crossline and time/depth gradients. Description This plugin calculates the inline, crossline or time/depth gradient using operators optimised for rotation invariance, ie equal response in all directions, proposed  by Kroon (2009) and Farid and Simoncelli(2004) . These provide more accurate alternatives to the Prewitt filter option of the OpendTect Convolve attribute for computing gradients. The attribute offers a choice of Kroon's 3x3x3, Farid and Simoncelli's 5x5x5 or Farid and Simoncelli's 7x7x7 operator. The following figures demonstrate the relative accuracy of these operators and the OpendTect Prewitt filter on a simple periodic signal (top left) with event dip angle shown top right. Gradients calculated using each operator are used to compute the event dip angle and the absolute dip angle error. The superior accuracy of the operators provided by this attribute is clear. Accuracy of the gradient attribute operators Input Parameters This attribute has 3 parameters: NAME DESCRIPTION Input Volume The input attribute volume. Output Gradient What to calculate - choice of Inline, Crossline or Z gradient. Operator What operator to use - choice of Kroon's 3x3x3, Farid's 5x5x5 or Farid's 7x7x7. Gradient attribute input parameter dialog",
            "title": "GradientAttrib",
            "url": "/OpendTect-Plugin-Docs/plugins/GradientAttrib.html"
        },
        {
            "tags": "plugin",
            "text": "This attribute plugin for the open source seismic interpretation platform OpendTect Version 6.0.0 or later performs time-frequency decomposition using a recursive filter. Description This plugin can be used as an alternative to the OpendTect FFT spectral decomposition attribute . It does spectral decomposition using Nilsen's (2007) time-frequency analysis algorithm which is a recursive filter approximation to a special case of the short time fourier transform (STFT). The primary advantage of this plugin over the standard OpendTect FFT spectral decomposition is that it can be evaluated significantly faster. As an example, under Linux on an Intel Core i5 for a 2000 sample per trace dataset, this attribute can generate a single frequency cube at 4000 traces per second. This is considerably faster than the 140-150 traces per second achieved when applying the OpendTect FFT spectral decomposition attribute. This processing speed advantage is reduced as the number of output frequencies increases but in this test case it still remains substantially faster even for output of up to 30 frequencies. Examples The output of the RSpec attribute (rfreq30) is visually identical and also highly correlated to the OpendTect FFT spectral decomposition (sdfreq30) as shown in the following crossplot of the two attributes. Crossplot of RSpecAttrib vs FFT Spectral Decomposition Input Parameters This attribute has 4 parameters: NAME DESCRIPTION Input Volume The attribute volume to be analysed. Time/Depth Gate This determines the position and time resolution of the analysis. The value from the gate centre is output - useful for analysing a zone offset from an horizon. Recommend setting the gate length equal to or less than the FFT window length you would used for the standard OpendTect FFT spectral decomposition. Output frequency When displaying the attribute in the tree this is the frequency slice that will be generated. Step This determines the set of frequencies that can be chosen when generating a frequency volume. RSpecAttrib input parameter dialog",
            "title": "RSpecAttrib",
            "url": "/OpendTect-Plugin-Docs/plugins/RSpecAttrib.html"
        },
        {
            "tags": "plugin",
            "text": "This plugin, for the open source seismic interpretation platform OpendTect Version 6.4.0 or later, exports OpendTect 3D horizon and attribute data to a GeoTIFF image. GeoTIFF is a public domain metadata standard which allows georeferencing information to be embedded within a TIFF image file. GeoTIFF image files are widely supported by GIS software. Description The plugin adds a \"Geotiff Export\" item to the Survey-Export main menu. Selecting the item opens a dialog box for selecting the 3D horizon and attributes to export and the destination file name. The horizon Z values and attributes values are exported to Float32 bands in the output image. The plugin supports exporting multiple attributes to a single GeoTIFF file, however some GIS packages may not have the flexibility to display individual bands from a Float32 multiband image (eg QGIS v3.6). If multiband images prove to be a problem the option exists to run the plugin multiple times and save each attribute to a separate GeoTIFF file. Notes The plugin requires the survey to have a projection based CRS defined. This plugin is actually part of the GeopackageExport plugin - see notes there as well OpendTect 3D horizon data displayed in a QGIS print layout Input Parameters",
            "title": "GeotiffExport",
            "url": "/OpendTect-Plugin-Docs/plugins/GeotiffExport.html"
        },
        {
            "tags": "plugin",
            "text": "This plugin, for the open source seismic interpretation platform OpendTect Version 6.4.0 or later, exports OpendTect data to a GeoPackage database. GeoPackage is an open, non-proprietary, platform-independent, self describing standards-based data format for geospatial data. Description The plugin adds a \"Geopackage Export\" item to the Survey-Export main menu. Selecting the item opens a tabbed dialog box for selecting the various elements to export and the destination file name. The following table shows the OpendTect data elements supported and the corresponding tables created in the exported GeoPackage database. OpendTect Item GeoPackage Table Name Geometry Notes Survey Box Survey Polygon Single attribute, the survey name 2D Line Geometry 2DLines LineString Single attribute, the line name 2D Line Stations 2DStations Points Two attributes, the line name and station number Random Lines RandomLines LineString Single attribute, the random line name Wells Wells Points Well surface location and 3 attributes, the well name, UWID and status (not currently set by OpendTect) Well Tracks WellTracks LineString Single attribute, the well name Well Markers WellMarkers Points Four attributes, well name, marker name, MD and TVDSS Open Polygons PolyLines LineString Single attribute, the polyline name. The z values of the polyline are not exported Closed Polygons Polygons Polygon Single attribute, the polygon name. The z values of the polygon are not exported 2D and 3D Horizons Set by the user Point Single attribute, the horizon z value in millisecs or metres depending on the Z domain of the survey Notes It is possible to append to an existing database. This is primarily used for exporting multiple horizons/attributes to the same GeoPackage. Appending does not overwrite items already in the GeoPackage it will just add another copy to the respective table. The plugin requires the survey to have a projection based CRS defined. On Windows the folder containing the plugin DLL's must be added to the PATH environment variable either by editing the corresponding system variable (Control Panel>System and Security>System - Advanced system settings - Environment Variables) or adding a line like \"@set PATH=%HOMEPATH%.od\\bin\\win64\\Release;%PATH%\" (adjust \"%HOMEPATH%.od\\bin\\win64\\Release\" to reflect your installation) to the bat script used to start OpendTect. The GeoPackage format is supported by major GIS software packages. The following figure shows display of data exported from OpendTect using the plugin in the open source GIS package, QGIS . OpendTect data displayed in QGIS Input Parameters The dialog box associated with the plugin has a file entry control to select the output file, a check box to allow appending to the output file instead of overwriting and 8 tabs to select the content to export: Survey tab 2D Lines tab Random Lines tab Wells tab Polylines tab Horizon tab GeoPackageExport plugin Horizon tab",
            "title": "GeopackageExport",
            "url": "/OpendTect-Plugin-Docs/plugins/GeopackageExport.html"
        },
        {
            "tags": "plugin",
            "text": "This attribute plugin for the open source seismic interpretation platform OpendTect calculates 6 attributes derived from AVO Polarization in the AVO Intercept-Gradient crossplot as described by Mahob and Castagna (2003) . Description The intercept-gradient crossplot is widely used for amplitude-variation-with-offset (AVO) analysis in hydrocarbon exploration.  The intercept is the zero offset or normal incidence reflection amplitude/coefficient of an event while the gradient is the change in reflection amplitude/coefficient with offset or incidence angle. Some authors refer to intercept as A or P and gradient as B or G. Traditional methods of AVO interpretation focus on individual sample points in isolation essentially treating them as reflection coefficients. Keho etal (2001) observed that this approach ignores the seismic wavelet. Convolving a seismic reflection coefficient with a typical seismic wavelet produces a series of points spread across all 4 quadrants of the AVO crossplot. Further distortions are introduced by residual time shifts across offsets and NMO stretch. Keho etal (2001) proposed analysing the AVO crossplot for small time windows of 0.5-1 times the wavelet wavelength as hodograms using the polarization angle as a key measure. Mahob and Castagna (2003) subsequently extended the analysis with a number of other measures to describe the hodogram. Example AVO hodogram crossplot for a 36 millisec TWT window This plugin calculates the 6 attributes (Background Polarization Angle, Event Polarization Angle, Polarization Angle Difference, Strength, Polarization Product and Quality) defined by Mahob and Castagna (2003) . The parameters are estimated by eigendecomposition of the covariance matrix for the intercept-gradient crossplot. EXAMPLE ATTRIBUTE Background Polarization Angle Polarization Angle for all AVO crossplot points over a user specified time/depth window and volume of traces. The polarization angle is the orientation of the largest eigenvector relative to the positive intercept axis and varies from -90 to 90 degrees. Event Polarization Angle Polarization  Angle for AVO crossplot points in the user specified event time/depth window. Recommend using 0.5-1 times the wavelength. The polarization angle is the orientation of the largest eigenvector relative to the positive intercept axis and varies from -90 to 90 degrees. Polarization Angle Difference The difference between the event and background polarization angles. Strength The Mahob and Castagna measure of the distance of the hodogram points from the origin within the event time/depth window. Polarization Product The product of the Strength and Polarization Angle Difference attributes. Quality This is the ratio of the eigenvalue difference to the eigenvalue sum. It is a measure of the linearity of the points in the intercept-gradient crossplot. It ranges from 0 to 1 with higher values indicating the analysis points have a more linear hodogram and more reliable results. Input Parameters These attributes have 3 required parameters and 3 extra parameters that may be required depending on the attribute being calculated: NAME DESCRIPTION Intercept The attribute volume to use as the zero offset or normal incidence reflection amplitude coefficient. If no intercept volume is available a near angle or offset stack can be used as an alternative. Gradient The attribute volume to use as the change in reflection amplitude/coefficient with offset at normal incidence. If no gradient volume is available, the difference between amplitudes on far and near angle or offset stacks can be used as an alternative. Output The attribute to calculate. There is a choice of Background Polarization Angle, Event Polarization Angle, Polarization Angle Difference, Strength, Polarization Product or Quality. Background time/depth gate (Optional) The time/depth gate used to estimate the Background Polarization Angle. Only required for the Background Polarization Angle, Polarization Angle Difference and Polarization Product attributes. Stepout (Optional) The extent of the trace volume used to estimate the Background Polarization Angle. Only required for the Background Polarization Angle, Polarization Angle Difference and Polarization Product attributes. Event time/depth gate (Optional) The time/depth gate used to estimate the Event Polarization Angle. Required for the Event Polarization, Polarization Angle Difference, Polarization Product and  Quality attributes. AVO Polarization Attribute Plugin input parameters",
            "title": "AVOPolarAttrib",
            "url": "/OpendTect-Plugin-Docs/plugins/AVOPolarAttrib.html"
        },
        {
            "tags": "plugin",
            "text": "This attribute plugin for the open source seismic interpretation platform OpendTect allows attributes to be developed in a scripting language like Python. Description With this plugin it is possible to calculate single and multitrace attributes outside of OpendTect using a user specified external application. The plugin supports multi-trace multi-attribute input and multi-attribute output as well as parallel execution. NOTE: Releases prior to 6.0.2 allowed multi-trace multi-attribute input only if all the attributes were in the same multi-attribute volume. In releases from 6.0.2 onward this limitation has been removed. Instead of doing the attribute calculation within OpendTect this plugin starts up a user specified external application and then reads and writes the trace data to/from the external application's stdin and stdout. The external application could be written in any programming language, compiled or interpreted, provided it has the Structure of a Conforming Application . This essentially means you can write a new OpendTect attribute in your computer language of choice and not have to delve into the internals of OpendTect. A reference implementation for writing external attributes in Python/Numpy (version 3) is available. This consists of a module extattrib.py that handles the stdin/stdout details and presents the trace data as a numpy array. Guides and Tips and Tricks to assist can be found in various Articles There are external attribute scripts for everything from dip estimation to filtering described in the External Attributes section of this documentation. Input Parameters This attribute has 3 required parameters and up to 9 optional parameters determined by the JSON Parameter String provided by the external attribute script: NAME DESCRIPTION Interpreter For external attributes written in a scripted language this field specifies the location of the  interpreter required to run the script, eg /usr/bin/python3 External File The external application to be used for attribute calculation. Input The input attribute to use External Attribute Plugin input parameters Cross Platform Setup Prior to release 5.10 and 6.0.0pre7-1 any attribute set containing external attributes could not be shared between Windows and Linux because the Interpeter and External File input fields contain platform specific file paths. Release 5.10 and 6.0.0pre7-1 introduced an optional mechanism to support cross platform attribute sets containing external attributes by using environment variables. Consider the following script for starting OpendTect on Linux: #!/bin/csh -f\nsetenv DTECT_SETTINGS \"$HOME/.od6\"\nsetenv OD_USER_PLUGIN_DIR \"$HOME/.od6\"\nsetenv EX_PYTHON \"/opt/anaconda3/bin/python\"\nsetenv OD_EX_DIR \"$HOME/Development/GIT_AREA/OpendTect-External-Attributes/\"\n/opt/seismic/OpendTect_6/6.0.0/start_dtect And an equivalent Windows command file: @set OD_USER_PLUGIN_DIR=%HOMEPATH%\\od6\n@set EX_PYTHON=C:\\Miniconda3\\python.exe\n@set OD_EX_DIR=E:\\Development\\GIT_AREA\\OpendTect-External-Attributes\\\nstart \"\" \"C:\\Program Files\\OpendTect_6\\6.0.0\\bin\\win64\\Release\\od_start_dtect.exe\" The environment variable EX_PYTHON points to the python interpreter for each platform and entering %EX_PYTHON% into the Interpreter input field ensures the platform appropriate interpreter is used. Any name can be used for the environment variable. The  environment variable OD_EX_DIR points to a root folder below which the attribute script files can be found. The setting in the Linux startup script points to a Linux folder. The corresponding setting in the Windows command file points to the same location via a network share. This environment variable name is hard wired into the code so this variable name cannot be changed. Note that the script files cam be located in subfolders of the OD_EX_DIR folder. This type of setup produces attribute set descriptions like this: 7.Definition: ExternalAttrib interpfile=%EX_PYTHON% exfile=%OD_EX_DIR%tests/ex_ui_test_all.py zmargin=[-1,1] stepout=1,1 selection=2 par0=0 par1=1 par2=2 par3=3 par4=4 par5=5 output=0 which can be used on either platform without change. Attribute sets created by release 5.0.10 and 6.0.0pre7-1 and later that use these environment variables will not work in earlier versions of the External Attribute plugin. JSON Parameter String The external application can specify a set of parameters as a JSON object string. The following keywords are supported: JSON KEYWORD Input (depreciated) TYPE String DESCRIPTION Specifies a label to appear beside the input attribute selection UI element.",
            "title": "ExternalAttrib",
            "url": "/OpendTect-Plugin-Docs/plugins/ExternalAttrib.html"
        },
        {
            "tags": "plugin",
            "text": "LTFAttrib This attribute plugin for the open source seismic interpretation platform OpendTect Version 6.0 or later performs time-frequency decomposition using local attributes. Description This is an implementation of the method of local time-frequency analysis described by Liu, G etal (2011) . The time-frequency decomposition uses least-squares inversion with shaping regularization. It is different to STFT (short time fourier transform) which divides the data into windows to  localize frequency content in time. This plugin is only available on Linux and requires a working installation of Madagascar with the Madagascar \"lib\" folder on the linker search path (eg: add ${RSFROOT}/lib to the LD_LIBRARY_PATH environment variable). The plugin provides an example of an attribute using the Madagascar libraries. This attribute can be unstable. The issue apppears to be in the Madagascar libraries as the same instabilites exist when the equivalent Madagascar command line program ( sftimefreq ) is applied. Examples The output of the LTF attribute (ltf30) is visually identical and also highly correlated to the OpendTect FFT spectral decomposition (sdfreq30) as shown in the following crossplot of the two attributes. Crossplot of LTFAttrib vs FFT Spectral Decomposition Input Parameters This attribute has 4 parameters: NAME DESCRIPTION Input Volume The attribute volume to be analysed. Frequency The frequency component to estimate. Smoothing Radius In shaping regularization this parameter controls the smoothness of the model. Iterations The number of inversion iterations. Margin Amount of data around the calculation sample to include in the calculation. Specified in number of smoothing radii. LTF Attributes input parameters",
            "title": "LTFAttrib",
            "url": "/OpendTect-Plugin-Docs/plugins/LTFAttrib.html"
        },
        {
            "tags": "plugin",
            "text": "This attribute plugin for the open source seismic interpretation platform OpendTect calculates 6 attributes based on different parameterizations of reflection intercept and gradient. Description The intercept-gradient crossplot is widely used for amplitude-variation-with-offset (AVO) analysis in hydrocarbon exploration.  The intercept is the zero offset or normal incidence reflection amplitude/coefficient of an event while the gradient is the change in reflection amplitude/coefficient with offset or incidence angle. Some authors refer to intercept as A or P and gradient as B or G. Modelling studies show that changes in subsurface rock properties such as lithology, porosity and pore fluid content result in systematic changes in intercept-gradient space. The following figure, adapted from the very informative paper on AVO by Foster etal (2010) , illustrates the ideal intercept-gradient crossplot response for a clastic sequence to changes in porosity and pore fluid. The Fluid Line or Background Trend is where reflections from shales and some wet sands that have little contrast in Vp/Vs plot. Ideal AVO crossplot for a clastic sequence Another popular classification of AVO effects on the intercept-gradient crossplot is the 3 class AVO scheme of Rutherford and Williams (1989) based on acoustic impedance contrasts with the addition of a 4th class for high porosity gas sands introduced by Castagna and Swan (1997) . The position of these 4 AVO classes on the intercept-gradient crossplot is shown in the following figure. AVO classes This plugin calculates 6 attributes which are essentially just coordinate transformations of the intercept and gradient that aim to highlight changes of a particular rock property based on the expected behaviour of clastic reservoir sequences. ATTRIBUTE DESCRIPTION Fluid Factor Fluid Factor is a reprojection of intercept/gradient coordinates that highlights deviation from the Fluid Line. As the name implies this attribute highlights changes related to fluid compressibility. The Fluid Factor was introduced by Smith and Gidlow (1987) . Lithology Factor Lithology Factor is the companion coordinate reprojection to Fluid Factor. It highlights changes parallel to the Fluid Line. Porosity Factor Porosity Factor is just Lithology Factor with the values above the fluid line reversed so the attribute magnitude always increases in the same sense as the effect of increasing porosity, i.e. the attribute magnitude increases to the upper left below the Fluid Line and to the lower right above the Fluid Line. Crossplot Angle Crossplot Angle is the angle between an intercept-gradient point and the Fluid Line. It runs from 0 to 180 below the Fluid Line measured counter-clockwise from the upper left projection of the Fluid Line. It runs from 0 to -180 above the Fluid Line measured counter-clockwise from the lower right projection of the Fluid Line. The Crossplot Angle and Deviation can be interpreted as the polar coordinates of a data point in the intercept-gradient crossplot space. Crossplot Deviation Crossplot Deviation is the distance from the crossplot origin. This attribute is most useful as a transparency mask to remove data close to the centre of the crossplot. AVO Class AVO Class classifies intercept-gradient points according to the 4 class AVO scheme of Rutherford and Williams (1989) and Castagna and Swan (1997). Points below the Fluid Line have a positive class number and those above have a negative class number. Input Parameters These attributes have 4 required parameters and 4 extra parameters that may be required depending on the attribute being calculated: NAME DESCRIPTION Intercept Volume The attribute volume to use as the zero offset or normal incidence reflection amplitude coefficient. If no intercept volume is available a near angle or offset stack can be used as an alternative. Gradient Volume The attribute volume to use as the change in reflection amplitude/coefficient with offset at normal incidence. If no gradient volume is available, the difference between amplitudes on far and near angle or offset stacks can be used as an alternative. Output The attribute to calculate. There is a choice of Fluid Factor, Lithology Factor, Porosity Factor, Crossplot Angle, Crossplot Deviation or AVO Class. Crossplot Slope The slope of the fluid line interpreted on the intercept-gradient crossplot. This can be read from the properties dialog of the crossplot tool. Intercept Standard Deviation (Optional) Standard deviation of the intercept volume. Only required for the Crossplot Angle and Crossplot Deviation attributes. This can be read from the 1D histogram tool in the crossplot table. Gradient Standard Deviation (Optional) Standard deviation of the gradient volume. Only required for the Crossplot Angle and Crossplot Deviation attributes. This can be read from the 1D histogram tool in the crossplot table. Correlation Coefficient (Optional) Correlation coefficient between the intercept and gradient volumes. Only required for the Crossplot Deviation attribute. This can be read from the properties dialog of the crossplot tool. Class 2 Intercept Offset Half width in intercept coordinates of the Class 2 region on the AVO Class crossplot. Only required for the AVO Class attribute. AVO Attribute Plugin input parameters",
            "title": "AVOAttrib",
            "url": "/OpendTect-Plugin-Docs/plugins/AVOAttrib.html"
        },
        {
            "tags": "plugin",
            "text": "This plugin, for the open source seismic interpretation platform OpendTect Version 6.4.0 or later, allows creation and editing of a file with Z shift, phase rotations and amplitude scaling corrections for 2D and 3D seismic in an OpendTect survey/project. The plugin also includes an attribute (Mistie Application) that will apply the corrections. In an ideal world we would be given 2D seismic data that has consistent Z, phase and amplitude scales. In the real world this doesn't always happen and 2D seismic interpretation projects accumulate inconsistencies as more data is added. The concept implemented by this plugin is the interpreter builds/maintains the correction table as they work through the data. The virtual corrected seismic from the Mistie Application attribute can be interpreted on the fly or the interpreter can generate a new adjusted dataset and interpret that. Future planned enhancements: Add an option to apply the Z shifts to an existing seismic interpretation Description The plugin provides components to: Estimate misties from seismic data Analyse the misties and estimate corrections to minimize the misties in a least squares sense Edit/Maintain a set of mistie corrections Attribute to apply the corrections. There are two alternative workflows to build a mistie correction file: Estimate the misties from the data and compute a mistie correction file in the Mistie Analysis dialog Manually build the mistie correction file in the Mistie Correction Editor Mistie Analysis The plugin adds a \"Mistie Analysis\" item to the Analysis main menu. Selecting the item opens the Mistie Analysis dialog: Mistie Analysis Actions associated with the toolbar buttons are: ICON DESCRIPTION Open the Mistie Estimation dialog to estimate misties from the seismic data. Existing contents of the mistie table are erased. Load mistie estimates from a previously saved file. Existing contents of the mistie table are erased. Save the current mistie estimates. If the current misties were loaded from a file then that will be overwritten, otherwise user will be asked to provide a new file name. Prompts for a file and saves the current mistie estimates. Prompts for another mistie file and merges the results with the mistie set currently active in the tool optionally keeping or replacing common items. Open the Correction Calculation dialog. Opens a web browser and displays an interactive dashboard report for the current misties and correction set active in the tool. Mistie Estimation The toolbar item in the Mistie Analysis dialog opens the following dialog to estimate misties from the seismic data using the method described by Bishop and Nunns (1994) : Mistie Estimation The user can: Select the data type (attribute) and which lines to include in the analysis Include and select a 3D seismic volume to include in the analysis Specify the trace interval along 2D lines to estimate the 2D to 3D misties, the average mistie is assigned to the 2D to 3D tie Limit the maximum time-shift or mistie to consider Specify a Z window for the cross correlation of traces at line interections The Apply button will initiate the estimation of the misties, when complete results are displayed in the Mistie Analysis dialog. Clicking the icon will generate a Mistie Report with histograms and scatterplot of the mistie estimates  for review. Mistie Correction Calculation The toolbar item in the Mistie Analysis dialog opens the following dialog to compute mistie corrections that minimize the root mean square (RMS) mistie after correction: Mistie correction calculation The user can: Optional select one or more line(s) to use as a reference. Reference lines will have Z, phase and amplitude corrections constrained to be 0, 0, 1 respectively and corrections will be computed only for  the non-reference lines. Selecting no lines will distribute corrections across all lines. Restrict calculation to intersections with a correlation coefficient (tie quality) above a minimum threshhold. The intersection quality can vary from 0.0 (no tie) to 1.0 (perfect tie). A cut-off of 0.5-0.6 should prevent unreliable mistie estimates being used to compute corrections. Control the maximum number of iterations used to calculate the corrections - the default value should be adequate in most circumstances. Control the convergence criteria that stops the iteration used to calulate the corrections - iterations stop if the change in the RMS mistie (after applying corrections) between successive iterations is less than the threshhold. Thresholds exist for the Z, phase and amplitude corrections. The default values should be adquate in most circumstances. The calculated corrections will be displayed in a new table dialog: Mistie correction viewer The toolbar buttons can be used to save the corrrections to a disk file. Mistie Report The toolbar item in the Mistie Analysis dialog generates and displays in the system web browser a graphical, html format dashboard of the mistie anaysis and correction calculation results. This includes tabulated data, histograms and a 3D scatterplot. Here is an example of a mistie report . Mistie Correction Editor The plugin adds a \"Mistie Corrections\" item to the Survey-Manage main menu. Selecting the item opens the Mistie Correction Editor. This tool can be used to manually create mistie correction files or modify files generated by the Mistie Correction Calculation . Mistie correction editor The editor has toolbar buttons to: ICON DESCRIPTION Create a mistie correction set with all the  2D lines in the project (with default corrections that make no change to the  data). Existing contents of the mistie table are erased. Load mistie corrections from a previously saved file. Existing contents of the mistie table are erased. Save the current mistie corrections. If the current corrections were loaded from a file then that will be overwritten, otherwise the user will be asked to provide a new file name. Prompts for a file and saves the current mistie corrections. Merge another mistie correction set file with the current set, optionally keeping or replacing the existing corrections where there is duplicate line/dataset names. Within the editor it is possible to: Add new lines/datasets and associated corrections Edit existing corrections RightMouseButton click on a row brings up a menu to insert or delete selected row(s) Limited clipboard copy and paste is available You can include corrections for a particular 3D seismic volume by using a line/dataset name of the form \"3D_XXXX\" where the \"XXXX\" is the volume name, eg note the \"3D_pstm\" in the above figure. Multiple unique \"3D_XXXX\" entries are allowed to specify corrections for different 3D volumes in the project. If a line doesn't need a correction it can be omitted from the set and default (no change) corrections will be assumed when the Mistie Application attribute is applied. A message (which can be safely ignored) is added to the log file when this occurs. The name in the line/dataset column must exactly match the project line name. Mistie Application Attribute The plugin adds a \"Mistie Application\" attribute to the list of OpendTect attributes. Mistie Application attribute input parameters The attribute parameters include: The input seismic volume to be corrected A file with the mistie correction set to apply Which corrections to apply When the attribute is displayed the shift, phase rotation and amplitude scalar for the line is read from the correction file and applied. Notes The default file extension for saved mistie estimates is \"mistie\" The default file extension for saved mistie corrections is \"miscor\" The default file location for all files is the Misc folder in the OpendTect survey/project folder All files are in a simple text format which can also be modified using a text editor",
            "title": "Mistie",
            "url": "/OpendTect-Plugin-Docs/plugins/Mistie.html"
        },
        {
            "tags": "plugin",
            "text": "This plugin, for the open source seismic interpretation platform OpendTect Version 6.4.0 or later, creates a 3D horizon/grid from the 2D and 3D horizon interpretation in an OpendTect survey/project. Description The plugin adds a \"Grid 2D-3D Horizon...\" item to the \"Processing|Create Horizon Output\" menu which opens a dialog box for: Selecting 2D and 3D seismic interpretation to grid Specifying the output horizon name, extent and inline /crossline interval Specifying a cropping polygon Specifying a set of fault polygon constraints Selecting the interpolation algorithm to use In the current release the plugin includes two gridding/interolation algorithms: Continuous curvature splines with tension - Wessel and Bercovici (1998) Inverse distance squared weighted averages If fault constraints are provided only input data on the same side of the fault is used to interpolate a grid node. Example of continuous curvature spline gridding without fault constraints Example of continuous curvature spline gridding with fault constraints Example of inverse distance squared gridding with fault constraints Input Parameters Grid 2D-3D horizon plugin input data selection dialog Grid 2D-3D horizon plugin input dialog, showing Bounding Box grid extent and continuous curvature interpolation settings Grid Extent: Two options available: Bounding Box - set the output horizon extent from the extent of the input data, adjusted to snap to the specified Inl/Crl steps Horizon - set the output horizon extent to match an existing horizon in the survey/project Inl/Crl Step - Under the BoundingBox Grid Extent option the output grid spacing can be specified relative to the 3D survey step/sampling Cropping Polygon - select a polygon to crop the grid output Fault Polygons - select  polygons to use as fault constraints during gridding. Suggest fault naming scheme that prefixes the polygons with \"f_horizon name\" to make them easy to select Algorithm - Local Continuous Curvature Tension Spline parameters: Search radius - only data within a square +/- this radius  is used to estimate a grid node Tension - the spline tensioning parameter, varies from 0 (equivalent to Minimum Curvature) to 1 (equivalent to an elastic membrane) Grid 2D-3D horizon plugin input dialog, showing Horizon grid extent settings and inverse distance squared interpolation settings Algorithm - Inverse Distance Squared parameters: Search radius (if checked) - only data within a square +/- this radius  is used to estimate a grid node, otherwise use all input data (subject to the fault constaints) for each grid node.",
            "title": "Grid 2D-3D Horizon",
            "url": "/OpendTect-Plugin-Docs/plugins/Grid2D-3D.html"
        },
        {
            "tags": "plugin filter",
            "text": "This attribute plugin for the open source seismic interpretation platform OpendTect applies a structure preserving Mean of Least Variance filter. Description This attribute is an implementation of a mean of least variance filter Schulze & Pearce (1993) where the analysis elements are all the possible planes through the sample points in the analysis block. This algorithm may be similar to that proposed by Al-Dossary & Wang (2011) . The sample variance for all samples on each analysis element is calculated and the output statistic (average, mean or element index) is output for the element with the least variance. The following figure shows the relationship between the geometry of the analysis elements and the element index. MLV Filter analysis elements Examples MLV 3 elements Input Parameters This attribute has 2 parameters: NAME DESCRIPTION Filter size Specifies a cube of samples centred  at the analysis location. Increasing the size will increase the degree of smoothing at the risk of smearing structural features. As the examples show it may be better to apply multiple passes of a small size filter than a single pass of a larger filter to reduce the risk of artifacts in the output. OpendTect makes it really easy to cascade multiple filter passes. Output statistic What the filter will output. The options are average, median or the element index. The element index is included for curiosity and quality control. Generally the default Average provides the most pleasing output. MLF Filter input parameters",
            "title": "MLVFilterAttrib",
            "url": "/OpendTect-Plugin-Docs/plugins/MLVFilter.html"
        },
        {
            "tags": "",
            "text": "AVOAttrib AVOPolarAttrib DataExtentHorizon ExternalAttrib GeopackageDisplay GeopackageExport GeotiffExport GradientAttrib Grid 2D-3D Horizon LTFAttrib MLVFilterAttrib Mistie RSpecAttrib",
            "title": "Plugins",
            "url": "/OpendTect-Plugin-Docs/plugins/index.html"
        },
        {
            "tags": "plugin",
            "text": "This is an extension of the GeopackageExport plugin that displays lines and polylines from a Geopackage database file over an OpendTect 3D horizon. Description The plugin adds a \"Geopackage Display\" item to the \"Add\" context menu of 3D Horizons in the scene tree. Selecting the item opens a dialog box for selecting the Geopackage file, the layer to display and the line color and width. Multiple layers can be displayed. Geopackage Display menu item Notes The plugin requires the survey to have a projection based CRS defined. This plugin is actually part of the GeopackageExport plugin - see notes there as well GIS data draped on an OpendTect 3D horizon",
            "title": "GeopackageDisplay",
            "url": "/OpendTect-Plugin-Docs/plugins/GeopackageDisplay.html"
        },
        {
            "tags": "",
            "text": "Introduction Because the Python ExternalAttrib script is running in a process started by the OpendTect application most standard methods to examine the script as it runs, eg using the standard Python debugger pdb , are not available. A solution is to use the Web-PDB Python module which allows the Python script to be debugged remotely in a web-browser. Web-PDB Installation Web-PDB is not included by default in most Python installations but it can be easily added using pip : pip install web-pdb Adding Web-PDB to a Script Adding Web-PDB to a script is just a matter of importing the module as shown on line 5 and adding a call to web_pdb.set_trace() as shown on line 19. The web_pdb.set_trace() call acts like a breakpoint and can be inserted as many times as required. For simplicity it is best to disable multi-threaded processing (add a Parallel: False line to the xa.params object) while debugging. Debugging with Web-PDB After adding Web-PDB to the ExternalAttrib script it will run to the first breakpoint where execution will be suspended and a web-UI opened at the default port 5555. Pointing a web browser at http://<your  machine hostname or IP>:5555 , eg http://127.0.0.1:5555 , should show an interface for debugging as above. The buttons provide control on the script execution, hover the mouse pointer over them to see tooltips for each. More complex pdb commands can be inserted in the entry at the bottom of the screen. Click the ? button for a list of useful pdb commands. Web-PDB and Multi-threaded Processing It is possible to use Web-PDB with a script that has multi-threaded processing enabled by replacing the initial web_pdb.set_trace call with: web_pdb.set_trace( port=-1 ) This will cause each Python process to select a random port between 32768 and 65536. Operating System specific commands can then be used to determine the ports opened, eg: On Linux: ss -lntu in a console window. On Windows: netstat -an in a command window. A web-UI will need to be opened for each port and each process will need to be stepped through all breakpoints for attribute execution to progress.",
            "title": "Python External Attribute Tips & Tricks - Debugging",
            "url": "/OpendTect-Plugin-Docs/articles/2018-06-08.html"
        },
        {
            "tags": "",
            "text": "Introduction It is possible to write information to the OpendTect logfile from inside a Python ExternalAttrib script. The global variable xa.logH (assuming the extattrib module has been imported using import extattrib as xa ) is a Python logger object . An Example On line 18 the Python logger is modified by adjusting the severity level of messages that will appear in the log file. By default only CRITICAL, ERROR and WARNING messages will be written. On line 22 a message is written to the logfile showing the full path to the Python interpreter executing the script. As this line is in the Compute Loop Initialisation section it is only written at each invocation of the script. On line 32 a message is written that identifies the location, minimum and maximum of the trace being processed. As this line is in the Compute Loop a message is output for every trace processed. The Result",
            "title": "Python External Attribute Tips & Tricks - Logging",
            "url": "/OpendTect-Plugin-Docs/articles/2018-06-06.html"
        },
        {
            "tags": "",
            "text": "Introduction This article will review the structure of a simple Python ExternalAttrib script, ex_dip.py , which converts inline and crossline dip to true dip and dip azimuth. It is an example of multi attribute, single trace input and output. Some basic understanding of Python and Numpy is assumed. Every Python attribute script has 5 sections. The Imports This is where external modules/libraries required by the script are loaded. At a minimum the script must load: the Python sys and os modules the Numpy module (the fundamental package for scientific computing with Python) the external attribute module (extattrib.py) Generally sys, os and Numpy will be part of the Python installation. The extattrib module is part of the external attribute scripts package and its location is unknown to the Python installation unless we help out. The sys.path.insert call on line 11 provides this help by extending the default search path for Python modules to include the parent folder of the folder containing the script. This reflects the folder structure of the external attribute scripts package, so if you develop scripts outside this structure then you will need to change line 11 appropriately to append the location of extattrib.py to the module search path. Of course if your script requires other Python modules (eg SciPy, Numba) then add the appropriate import statements in this section. The Parameters The xa.params global variable must be assigned a JSON object string describing the input parameters for the script. This JSON string is used by the plugin to build an input dialog box. This attribute is very simple specifying just 2 input volumes and 2 output volumes and a url for documentation. The plugin dynamically builds the following input dialog for this script: A variety of other input elements can be specified to build more complex input dialogs. See the JSON Parameter String section of the plugin documentation for full details or look at other scripts to see what is possible. The Compute Loop Initialisation The doCompute function is where the attribute calculation occurs. The function is divided into 2 parts some initialisation and the \"while True:\" loop, discussed in the next section, where the calculations actually take place. Any code in this initialisation section will be executed just once when the attribute script is run and is a good place to calculate constants for use in the Compute Loop. This particular script shows how information stored in the SeismicInfo Block can be used to calculate some constants purely as an example. This attribute is so simple that no initialisation is actually required. The Compute Loop This is where the attribute calculation takes place. The xa.doInput() and xa.doOutput() function calls control the input and output of seismic trace data between the script and OpendTect. Generally these should be the first and last statements within the compute loop. Within the compute loop, some information about the current trace data such as the number of samples and the inline and crossline location are provided in the TraceInfo Block . These can be accessed using constructs like xa.TI['nrsamp'] . This information is not required for this particular script. The global Numpy array xa.Input contains the input trace data. xa.Input['name of input attribute'] returns a Numpy array with the trace data for the current compute location. The shape of this Numpy array depends on the traces stepouts required by the attribute. As this particular script uses just single trace input (inline and crossline step out of 0) the Numpy array has a shape of (1,1,xa.TI['nrsamp']) . In the more general case of a multi-trace attribute the Numpy array shape would be (xa.SI['nrinl'], xa.SI['nrcrl'], xa.TI['nrsamp']) and the input trace at the current location would be at the centre of the array, ie at index [xa.SI['nrinl']//2, xa.SI['nrcrl']//2,...] . Attribute ouput must be put into the xa.Output global Numpy array before the xa.doOutput() function call. Each element (eg xa.Output['name of output attribute'] ) of the output array must have a shape of (1,1,xa.TI['nrsamp']) The Postamble This section is just boilerplate code that apprears in every attribute script which should never be changed.",
            "title": "Anatomy of a Python External Attribute",
            "url": "/OpendTect-Plugin-Docs/articles/2018-06-04.html"
        },
        {
            "tags": "",
            "text": "Summary The potential to offload calculations to the graphics processing unit (GPU) on modern graphics cards is a trending topic. I was curious if this could also apply to seismic attribute calculation in OpendTect , so I implemented AVO polarization angle estimation as described by Mahob and Castagna (2003) using 3 different approaches: using loops for all the linear algebra and OpendTect's multi dimensional arrays (ArrayNDImpl) which I refer to as the Normal method; using the Eigen linear algebra C++ template library (the Eigen method) and using the ArrayFire linear algebra library for GPU's (the ArrayFire method). The first 2 options only use the central processing unit (CPU). ArrayFire also supports CPU calculation but for this review only the GPU capabilities were evaluated. In all cases benchmarks were run with and without OpendTect's multi-threaded processing support. Results are summarised in the following graph showing performance relative to the single threaded Normal method for a range of input data stepouts (higher performance numbers are better): The primary observations are: Both Eigen and ArrayFire can be used relatively easily within OpendTect 6.4 attribute plugins; OpendTect's multi-threaded processing support offers the most performance enhancement so developing the algorithm to enable multi-threading should be the first aim; The Eigen library offers a noticeable performance enhancement of up to 20% (relative to explicit coding of the linear algebra) for single trace and low-medium stepout attributes. Algorithms can also be expressed in fewer lines of code that is simpler to understand. The ArrayFire library makes it relatively easy to access the GPU compute power on the graphics card but the overhead of transferring data from the CPU to the GPU is significant and can result in poorer performance in some cases. The scale and/or compute complexity of the calculations will determine if there is any benefit to GPU calculations. In general this will require benchmarking of the particular algorithm. The code used in this evaluation is available in my OpendTect-Plugins GitHub repository. Related details are described below. Hardware Configuration Intel Core i5-3470 CPU @ 3.2Ghz 16GiB RAM GeForce GTX1050 Ti with 4GiB RAM Sofware Configuration Operating System: x86_64 GNU/Linux 4.2.0 Software: OpendTect 6.4.2 gcc 8.2.1 Eigen 3.3.7 ArrayFire 3.6.1 CUDA Toolkit 10, Driver: 415.25, CUDA Compute 6.1 Implementation The attribute plugin source code is in my OpendTect-Plugins GitHub repository in the: NoRelease/AVOPolar and NoRelease/uiAVOPolar folders. The plugin user interface is shown in the following image: A comparison of the compute code for each method is shown below. All code assumes multi-trace intercept and gradient data in the 2D arrays with dimensions ( sz x ntraces ) named A and B respectively. Comparison of the code reveals both Eigen and ArrayFire allow significantly more concise and clearer coding of linear algebra calculations. Normal Method Array1DImpl < double > A2 ( sz ); Array1DImpl < double > B2 ( sz ); Array1DImpl < double > AB ( sz ); for ( int idx = 0 ; idx < sz ; idx ++ ) { double A2v = 0.0 ; double B2v = 0.0 ; double ABv = 0.0 ; for ( int trcidx = 0 ; trcidx < ntraces ; trcidx ++ ) { A2v += ( double ) A . get ( trcidx , idx ) * ( double ) A . get ( trcidx , idx ); ABv += A . get ( trcidx , idx ) * B . get ( trcidx , idx ); B2v += B . get ( trcidx , idx ) * B . get ( trcidx , idx ); } A2 . set ( idx , A2v ); B2 . set ( idx , B2v ); AB . set ( idx , ABv ); } Array1DImpl < double > A2win ( sz ); windowedOps :: sum ( A2 , sampgateBG_ . width (), A2win ); Array1DImpl < double > B2win ( sz ); windowedOps :: sum ( B2 , sampgateBG_ . width (), B2win ); Array1DImpl < double > ABwin ( sz ); windowedOps :: sum ( AB , sampgateBG_ . width (), ABwin ); for ( int idx = 0 ; idx < sz ; idx ++ ) { double ABv = ABwin . get ( idx ); double A2mB2 = A2win . get ( idx ) - B2win . get ( idx ); double d = sqrt ( 4.0 * ABv * ABv + A2mB2 * A2mB2 ); result . set ( idx , atan2 ( 2.0 * ABv , A2mB2 + d ) / M_PI * 180.0 ); } for ( int idx = 0 ; idx < nrsamples ; idx ++ ) setOutputValue ( output , 0 , idx , z0 , result ( idx - sampgateBG_ . start )); Eigen Method Eigen :: ArrayXd A2 = A . square (). rowwise (). sum (); Eigen :: ArrayXd B2 = B . square (). rowwise (). sum (); Eigen :: ArrayXd AB = ( A * B ). rowwise (). sum (); Eigen :: ArrayXd A2win ( sz ); windowedOpsEigen :: sum ( A2 , sampgateBG_ . width (), A2win ); Eigen :: ArrayXd B2win ( sz ); windowedOpsEigen :: sum ( B2 , sampgateBG_ . width (), B2win ); Eigen :: ArrayXd ABwin ( sz ); windowedOpsEigen :: sum ( AB , sampgateBG_ . width (), ABwin ); Eigen :: ArrayXd A2mB2 = A2win - B2win ; Eigen :: ArrayXd result = ( 2.0 * ABwin / ( A2mB2 + ( 4.0 * ABwin . square () + A2mB2 . square ()). sqrt ())). atan () / M_PI * 180.0 ; for ( int idx = 0 ; idx < nrsamples ; idx ++ ) setOutputValue ( output , 0 , idx , z0 , result ( idx - sampgateBG_ . start )); ArrayFire Method af :: array A2 = af :: sum ( A * A , 1 ); af :: array B2 = af :: sum ( B * B , 1 ); af :: array AB = af :: sum ( A * B , 1 ); af :: array kernel = af :: constant ( ( double ) 1.0 , sampgateBG_ . width (), 1 ); af :: array A2win = af :: convolve1 ( A2 , kernel ); af :: array B2win = af :: convolve1 ( B2 , kernel ); af :: array ABwin = af :: convolve1 ( AB , kernel ); af :: array A2mB2 = A2win - B2win ; af :: array result = af :: atan2 ( 2.0 * ABwin , A2mB2 + af :: sqrt ( 4.0 * ABwin * ABwin + A2mB2 * A2mB2 )) / M_PI * 180.0 ; double * resbuf = result . host < double > (); for ( int idx = 0 ; idx < nrsamples ; idx ++ ) setOutputValue ( output , 0 , idx , z0 , resbuf [ idx - sampgateBG_ . start ]); af :: freeHost ( resbuf ); Method Attribute definitions were created for a range of stepouts, using a fixed window length, with/without multi-threading for each of the methods (Normal, Eigen and ArrayFire) Input data volumes with ~100,000 traces were preloaded into RAM The attributes were run using the OpendTect Processing|Create Seismic Output|Attributes|Single Attribute| menu item. Elapsed time to evaluate the attribute were computed from the start and finish times reported in the Progress Viewer Repeat runs conducted to verify consistency of the results.",
            "title": "GPU vs CPU Benchmarks for OpendTect Attribute Plugins",
            "url": "/OpendTect-Plugin-Docs/articles/2019_01_07.html"
        },
        {
            "tags": "",
            "text": "GPU vs CPU Benchmarks for OpendTect Attribute Plugins 07-Jan-2019",
            "title": "Articles",
            "url": "/OpendTect-Plugin-Docs/articles/index.html"
        },
        {
            "tags": "",
            "text": "GeopackageDisplay Mistie LTFAttrib DataExtentHorizon GradientAttrib RSpecAttrib GeotiffExport GeopackageExport AVOPolarAttrib ExternalAttrib AVOAttrib Grid 2D-3D Horizon",
            "title": "plugin",
            "url": "/OpendTect-Plugin-Docs/tag/plugin/"
        },
        {
            "tags": "",
            "text": "ZC Block AVO Intercept and Gradient Add Noise Time Delay Estimation",
            "title": "external-attribute",
            "url": "/OpendTect-Plugin-Docs/tag/external-attribute/"
        },
        {
            "tags": "",
            "text": "LPA Smoothing Spatial Filter - Circular Spatial Filter - Rectangular Vector Filter",
            "title": "external-attribute filter",
            "url": "/OpendTect-Plugin-Docs/tag/external-attribute filter/"
        },
        {
            "tags": "",
            "text": "Dip and Azimuth",
            "title": "external-attribute structure",
            "url": "/OpendTect-Plugin-Docs/tag/external-attribute structure/"
        },
        {
            "tags": "",
            "text": "MLVFilterAttrib",
            "title": "plugin filter",
            "url": "/OpendTect-Plugin-Docs/tag/plugin filter/"
        }
    ]
}